# Champion-Challenger Model Lifecycle Configuration

# Data Configuration
data:
  input_path: "data/raw/"
  processed_path: "data/processed/"
  validation_split: 0.2
  test_split: 0.1
  target_column: "target"
  feature_columns: []
  
# Ludwig Training Configuration
ludwig:
  config_path: "config/ludwig_config.yaml"
  output_directory: "models/ludwig_output/"
  experiment_name: "ludwig_training"
  
# MLflow Configuration
mlflow:
  tracking_uri: "http://localhost:5001"
  experiment_name: "champion_challenger_lifecycle"
  model_registry_name: "production_models"
  artifact_location: "s3://mlflow-artifacts/"
  
# Champion-Challenger Strategy
champion_challenger:
  evaluation_metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
    - "auc_roc"
  champion_threshold: 0.05  # Minimum improvement required
  challenger_evaluation_period: 7  # days
  shadow_mode_duration: 14  # days
  auto_promotion: true
  
# Deployment Configuration
deployment:
  champion_endpoint: "http://champion-model:8000"
  challenger_endpoint: "http://challenger-model:8001"
  shadow_mode: true
  traffic_split:
    champion: 0.9
    challenger: 0.1
  container_registry: "your-registry.com"
  
# Monitoring Configuration
monitoring:
  metrics_collection_interval: 300  # seconds
  alert_thresholds:
    accuracy_drop: 0.05
    latency_increase: 2.0  # seconds
    error_rate: 0.01
  prometheus_endpoint: "http://prometheus:9090"
  grafana_endpoint: "http://grafana:3000"
  
# Database Configuration
database:
  url: "postgresql://mlops_user:mlops_password@localhost:5433/mlops"
  model_metadata_table: "model_metadata"
  performance_metrics_table: "performance_metrics"
  
# Logging Configuration
logging:
  level: "INFO"
  format: "{time} | {level} | {name} | {message}"
  file_path: "logs/mlops.log"
  rotation: "1 day"
  retention: "30 days"
